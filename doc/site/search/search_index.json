{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to SIST AI Cluster \u8fd9\u662f\u4e00\u4efd\u7b80\u5355\u7684\u5b98\u65b9\u6587\u6863 \u5982\u679c\u4f60\u662f\u4e2a\u65b0\u624b \u5305\u62ec\u4f46\u4e0d\u9650\u4e8e: 1. \u7b2c\u4e00\u6b21\u4f7f\u7528linux\u7cfb\u7edf, \u53ea\u61c2\u5f97\u7b80\u5355\u7684cd, ls\u6307\u4ee4 2. \u4e0d\u77e5\u9053GPU\u548cCPU, \u5185\u5b58\u548c\u786c\u76d8\u7684\u533a\u522b 3. \u4e0d\u77e5\u9053\u5982\u4f55\u5b89\u88c5\u6240\u9700\u8981\u7684\u8f6f\u4ef6 \u8bf7 \u5982\u679c\u4f60\u662f\u4e2a\u8001\u624b \u5982\u679c\u4f60\u5bf9AI\u96c6\u7fa4\u7684\u73b0\u6709\u914d\u7f6e\u4e0d\u6ee1\u610f, \u79fb\u6b65 \u8ba8\u8bba\u533a","title":"Home"},{"location":"#welcome-to-sist-ai-cluster","text":"\u8fd9\u662f\u4e00\u4efd\u7b80\u5355\u7684\u5b98\u65b9\u6587\u6863","title":"Welcome to SIST AI Cluster"},{"location":"#_1","text":"\u5305\u62ec\u4f46\u4e0d\u9650\u4e8e: 1. \u7b2c\u4e00\u6b21\u4f7f\u7528linux\u7cfb\u7edf, \u53ea\u61c2\u5f97\u7b80\u5355\u7684cd, ls\u6307\u4ee4 2. \u4e0d\u77e5\u9053GPU\u548cCPU, \u5185\u5b58\u548c\u786c\u76d8\u7684\u533a\u522b 3. \u4e0d\u77e5\u9053\u5982\u4f55\u5b89\u88c5\u6240\u9700\u8981\u7684\u8f6f\u4ef6 \u8bf7","title":"\u5982\u679c\u4f60\u662f\u4e2a\u65b0\u624b"},{"location":"#_2","text":"\u5982\u679c\u4f60\u5bf9AI\u96c6\u7fa4\u7684\u73b0\u6709\u914d\u7f6e\u4e0d\u6ee1\u610f, \u79fb\u6b65 \u8ba8\u8bba\u533a","title":"\u5982\u679c\u4f60\u662f\u4e2a\u8001\u624b"},{"location":"QA_cluster/","text":"\u96c6\u7fa4\u7ba1\u7406\u76f8\u5173\u95ee\u9898 1. \u6211\u7684home\u76ee\u5f55\u5230\u5e95\u662f/root\u8fd8\u662f/home/name? 2. \u5fd8\u8bb0\u5bc6\u7801\u600e\u4e48\u529e? 3. \u5982\u4f55\u67e5\u770b\u6211\u73b0\u5728\u6709\u54ea\u4e9bnode\u7684\u6743\u9650? 4. \u5f53\u524d\u5bb9\u5668\u5df2\u7ecf\u88ab\u6211\u641e\u5f97\u574f\u7684\u4e0d\u80fd\u7528\u4e86, \u80fd\u5426\u7533\u8bf7\u4e00\u4e2a\u65b0\u5bb9\u5668? 5. \u6211\u7533\u8bf7\u7684\u4e34\u65f6\u6743\u9650\u5230\u671f\u4e86\u4e4b\u540e\u6240\u6709\u6587\u4ef6\u662f\u5426\u5220\u9664? 6. \u6211\u7684\u5b58\u50a8\u7a7a\u95f4\u4e0d\u591f\u7528\u4e86\u600e\u4e48\u529e?","title":"\u96c6\u7fa4\u7ba1\u7406\u76f8\u5173"},{"location":"QA_cluster/#_1","text":"","title":"\u96c6\u7fa4\u7ba1\u7406\u76f8\u5173\u95ee\u9898"},{"location":"QA_cluster/#1-homeroothomename","text":"","title":"1. \u6211\u7684home\u76ee\u5f55\u5230\u5e95\u662f/root\u8fd8\u662f/home/name?"},{"location":"QA_cluster/#2","text":"","title":"2. \u5fd8\u8bb0\u5bc6\u7801\u600e\u4e48\u529e?"},{"location":"QA_cluster/#3-node","text":"","title":"3. \u5982\u4f55\u67e5\u770b\u6211\u73b0\u5728\u6709\u54ea\u4e9bnode\u7684\u6743\u9650?"},{"location":"QA_cluster/#4","text":"","title":"4. \u5f53\u524d\u5bb9\u5668\u5df2\u7ecf\u88ab\u6211\u641e\u5f97\u574f\u7684\u4e0d\u80fd\u7528\u4e86, \u80fd\u5426\u7533\u8bf7\u4e00\u4e2a\u65b0\u5bb9\u5668?"},{"location":"QA_cluster/#5","text":"","title":"5. \u6211\u7533\u8bf7\u7684\u4e34\u65f6\u6743\u9650\u5230\u671f\u4e86\u4e4b\u540e\u6240\u6709\u6587\u4ef6\u662f\u5426\u5220\u9664?"},{"location":"QA_cluster/#6","text":"","title":"6. \u6211\u7684\u5b58\u50a8\u7a7a\u95f4\u4e0d\u591f\u7528\u4e86\u600e\u4e48\u529e?"},{"location":"QA_container/","text":"\u5bb9\u5668\u914d\u7f6e\u76f8\u5173\u95ee\u9898 \u5982\u4f55\u4e0a\u4f20\u6587\u4ef6\u5230\u96c6\u7fa4? / \u5982\u4f55\u4ece\u96c6\u7fa4\u4e0b\u8f7d\u6587\u4ef6? scp \u4e86\u89e3\u4e00\u4e0b # Copy local folder \"/home/username/local-dir\" to AI cluster directory \"/home/username/\" scp -r /home/username/local-dir username@10.19.124.11:/home/username/ # Copy file \"/home/username/project1/result.txt\" from AI cluster to path \"/home/username/results\" on local PC scp -r username@10.19.124.11:/home/username/project1/result.txt /home/username/results/ \u5982\u4f55\u67e5\u770bGPU\u4f7f\u7528\u60c5\u51b5? NVIDIA\u9a71\u52a8\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u547d\u4ee4\u884c\u5de5\u5177 nvidia-smi : # root @ piaozx.node01 in ~ [12:10:23] $ nvidia-smi Mon Aug 27 12:10:25 2018 +-----------------------------------------------------------------------------+ | NVIDIA-SMI 387.26 Driver Version: 387.26 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | |===============================+======================+======================| | 0 Tesla M40 24GB Off | 00000000:02:00.0 Off | 0 | | N/A 56C P0 175W / 250W | 2657MiB / 22939MiB | 98% Default | +-------------------------------+----------------------+----------------------+ | 1 Tesla M40 24GB Off | 00000000:03:00.0 Off | 0 | | N/A 49C P0 140W / 250W | 648MiB / 22939MiB | 91% Default | +-------------------------------+----------------------+----------------------+ | 2 Tesla M40 24GB Off | 00000000:83:00.0 Off | 0 | | N/A 55C P0 175W / 250W | 1126MiB / 22939MiB | 98% Default | +-------------------------------+----------------------+----------------------+ | 3 Tesla M40 24GB Off | 00000000:84:00.0 Off | 0 | | N/A 46C P0 142W / 250W | 648MiB / 22939MiB | 71% Default | +-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+ | Processes: GPU Memory | | GPU PID Type Process name Usage | |=============================================================================| | 0 28713 C python 1317MiB | | 1 14924 C python 636MiB | | 2 16059 C python 1115MiB | | 3 19563 C python 636MiB | +-----------------------------------------------------------------------------+ \u663e\u7136, \u8fd9\u4e2a\u5de5\u5177\u53ea\u80fd\u663e\u793a\u4e00\u4e9b\u57fa\u672c\u4fe1\u606f, \u4e00\u4e9b\u4f60\u66f4\u5173\u5fc3\u7684\u4fe1\u606f(\u8c01\u5728\u8dd1\u7a0b\u5e8f? \u8dd1\u4e86\u591a\u4e45\u4e86?)\u53ef\u4ee5\u4ece AI\u96c6\u7fa4GPU Status \u83b7\u53d6: \u5982\u4f55\u67e5\u770bnvidia-driver\u7248\u672c? / cuda\u7248\u672c? / cudnn\u7248\u672c? \u5982\u4f55\u67e5\u770bpython\u7248\u672c? / pytorch\u7248\u672c? / tensorflow\u7248\u672c? \u663e\u5b58\u88ab\u770b\u4e0d\u89c1\u7684\u8fdb\u7a0b\u5360\u636e\u600e\u4e48\u529e? # root @ piaozx.node01 in ~ [12:10:23] $ nvidia-smi Mon Aug 27 12:10:25 2018 +-----------------------------------------------------------------------------+ | NVIDIA-SMI 387.26 Driver Version: 387.26 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | |===============================+======================+======================| | 0 Tesla M40 24GB Off | 00000000:02:00.0 Off | 0 | | N/A 56C P0 175W / 250W | 2657MiB / 22939MiB | 0% Default | +-------------------------------+----------------------+----------------------+ | 1 Tesla M40 24GB Off | 00000000:03:00.0 Off | 0 | | N/A 49C P0 140W / 250W | 648MiB / 22939MiB | 0% Default | +-------------------------------+----------------------+----------------------+ | 2 Tesla M40 24GB Off | 00000000:83:00.0 Off | 0 | | N/A 55C P0 175W / 250W | 1126MiB / 22939MiB | 0% Default | +-------------------------------+----------------------+----------------------+ | 3 Tesla M40 24GB Off | 00000000:84:00.0 Off | 0 | | N/A 46C P0 142W / 250W | 648MiB / 22939MiB | 0% Default | +-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+ | Processes: GPU Memory | | GPU PID Type Process name Usage | |=============================================================================| | | | | | | | | +-----------------------------------------------------------------------------+ \u5982\u4f55\u5f00\u542fjupyter? \u5982\u4f55\u5f00\u542fvisdom? \u5982\u4f55\u521b\u5efapython\u7684\u865a\u62df\u73af\u5883? \u5982\u4f55\u914d\u7f6e\u548c\u4f7f\u7528screen / tmux? zsh\u662f\u4ec0\u4e48, \u5982\u4f55\u914d\u7f6e\u548c\u4f7f\u7528zsh?","title":"\u5bb9\u5668\u914d\u7f6e\u76f8\u5173"},{"location":"QA_container/#_1","text":"","title":"\u5bb9\u5668\u914d\u7f6e\u76f8\u5173\u95ee\u9898"},{"location":"QA_container/#_2","text":"scp \u4e86\u89e3\u4e00\u4e0b # Copy local folder \"/home/username/local-dir\" to AI cluster directory \"/home/username/\" scp -r /home/username/local-dir username@10.19.124.11:/home/username/ # Copy file \"/home/username/project1/result.txt\" from AI cluster to path \"/home/username/results\" on local PC scp -r username@10.19.124.11:/home/username/project1/result.txt /home/username/results/","title":"\u5982\u4f55\u4e0a\u4f20\u6587\u4ef6\u5230\u96c6\u7fa4? / \u5982\u4f55\u4ece\u96c6\u7fa4\u4e0b\u8f7d\u6587\u4ef6?"},{"location":"QA_container/#gpu","text":"NVIDIA\u9a71\u52a8\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u547d\u4ee4\u884c\u5de5\u5177 nvidia-smi : # root @ piaozx.node01 in ~ [12:10:23] $ nvidia-smi Mon Aug 27 12:10:25 2018 +-----------------------------------------------------------------------------+ | NVIDIA-SMI 387.26 Driver Version: 387.26 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | |===============================+======================+======================| | 0 Tesla M40 24GB Off | 00000000:02:00.0 Off | 0 | | N/A 56C P0 175W / 250W | 2657MiB / 22939MiB | 98% Default | +-------------------------------+----------------------+----------------------+ | 1 Tesla M40 24GB Off | 00000000:03:00.0 Off | 0 | | N/A 49C P0 140W / 250W | 648MiB / 22939MiB | 91% Default | +-------------------------------+----------------------+----------------------+ | 2 Tesla M40 24GB Off | 00000000:83:00.0 Off | 0 | | N/A 55C P0 175W / 250W | 1126MiB / 22939MiB | 98% Default | +-------------------------------+----------------------+----------------------+ | 3 Tesla M40 24GB Off | 00000000:84:00.0 Off | 0 | | N/A 46C P0 142W / 250W | 648MiB / 22939MiB | 71% Default | +-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+ | Processes: GPU Memory | | GPU PID Type Process name Usage | |=============================================================================| | 0 28713 C python 1317MiB | | 1 14924 C python 636MiB | | 2 16059 C python 1115MiB | | 3 19563 C python 636MiB | +-----------------------------------------------------------------------------+ \u663e\u7136, \u8fd9\u4e2a\u5de5\u5177\u53ea\u80fd\u663e\u793a\u4e00\u4e9b\u57fa\u672c\u4fe1\u606f, \u4e00\u4e9b\u4f60\u66f4\u5173\u5fc3\u7684\u4fe1\u606f(\u8c01\u5728\u8dd1\u7a0b\u5e8f? \u8dd1\u4e86\u591a\u4e45\u4e86?)\u53ef\u4ee5\u4ece AI\u96c6\u7fa4GPU Status \u83b7\u53d6:","title":"\u5982\u4f55\u67e5\u770bGPU\u4f7f\u7528\u60c5\u51b5?"},{"location":"QA_container/#nvidia-driver-cuda-cudnn","text":"","title":"\u5982\u4f55\u67e5\u770bnvidia-driver\u7248\u672c? / cuda\u7248\u672c? / cudnn\u7248\u672c?"},{"location":"QA_container/#python-pytorch-tensorflow","text":"","title":"\u5982\u4f55\u67e5\u770bpython\u7248\u672c? / pytorch\u7248\u672c? / tensorflow\u7248\u672c?"},{"location":"QA_container/#_3","text":"# root @ piaozx.node01 in ~ [12:10:23] $ nvidia-smi Mon Aug 27 12:10:25 2018 +-----------------------------------------------------------------------------+ | NVIDIA-SMI 387.26 Driver Version: 387.26 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | |===============================+======================+======================| | 0 Tesla M40 24GB Off | 00000000:02:00.0 Off | 0 | | N/A 56C P0 175W / 250W | 2657MiB / 22939MiB | 0% Default | +-------------------------------+----------------------+----------------------+ | 1 Tesla M40 24GB Off | 00000000:03:00.0 Off | 0 | | N/A 49C P0 140W / 250W | 648MiB / 22939MiB | 0% Default | +-------------------------------+----------------------+----------------------+ | 2 Tesla M40 24GB Off | 00000000:83:00.0 Off | 0 | | N/A 55C P0 175W / 250W | 1126MiB / 22939MiB | 0% Default | +-------------------------------+----------------------+----------------------+ | 3 Tesla M40 24GB Off | 00000000:84:00.0 Off | 0 | | N/A 46C P0 142W / 250W | 648MiB / 22939MiB | 0% Default | +-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+ | Processes: GPU Memory | | GPU PID Type Process name Usage | |=============================================================================| | | | | | | | | +-----------------------------------------------------------------------------+","title":"\u663e\u5b58\u88ab\u770b\u4e0d\u89c1\u7684\u8fdb\u7a0b\u5360\u636e\u600e\u4e48\u529e?"},{"location":"QA_container/#jupyter","text":"","title":"\u5982\u4f55\u5f00\u542fjupyter?"},{"location":"QA_container/#visdom","text":"","title":"\u5982\u4f55\u5f00\u542fvisdom?"},{"location":"QA_container/#python","text":"","title":"\u5982\u4f55\u521b\u5efapython\u7684\u865a\u62df\u73af\u5883?"},{"location":"QA_container/#screen-tmux","text":"","title":"\u5982\u4f55\u914d\u7f6e\u548c\u4f7f\u7528screen / tmux?"},{"location":"QA_container/#zsh-zsh","text":"","title":"zsh\u662f\u4ec0\u4e48, \u5982\u4f55\u914d\u7f6e\u548c\u4f7f\u7528zsh?"},{"location":"about/","text":"\u5982\u679c\u4f60\u6709\u4ec0\u4e48\u95ee\u9898, \u79fb\u6b65 \u8ba8\u8bba\u533a . \u6216\u8005\u8054\u7cfb\u96c6\u7fa4\u7ba1\u7406\u5458\u534f\u52a9\u89e3\u51b3","title":"About"},{"location":"moral/","text":"\u9053\u5fb7\u51c6\u5219 \u96c6\u7fa4\u662f\u5927\u5bb6\u7684, \u4e0d\u8981\u6076\u610f\u5360\u7528\u4ed6\u4eba\u7684\u5361\u6765\u8dd1\u7a0b\u5e8f \u53ca\u65f6\u6e05\u7406\u4e0d\u9700\u8981\u7684\u6587\u4ef6, \u4e0d\u8981\u4e00\u4e2aepoch\u5b58\u4e00\u4e2a\u6a21\u578b\u8fd8\u4e0d\u5220 \u4e0b\u7ebf\u554a","title":"\u9053\u5fb7\u51c6\u5219"},{"location":"moral/#_1","text":"\u96c6\u7fa4\u662f\u5927\u5bb6\u7684, \u4e0d\u8981\u6076\u610f\u5360\u7528\u4ed6\u4eba\u7684\u5361\u6765\u8dd1\u7a0b\u5e8f \u53ca\u65f6\u6e05\u7406\u4e0d\u9700\u8981\u7684\u6587\u4ef6, \u4e0d\u8981\u4e00\u4e2aepoch\u5b58\u4e00\u4e2a\u6a21\u578b\u8fd8\u4e0d\u5220 \u4e0b\u7ebf\u554a","title":"\u9053\u5fb7\u51c6\u5219"},{"location":"start/","text":"\u7533\u8bf7\u96c6\u7fa4\u8d26\u53f7\u53ca\u6743\u9650 \u6240\u6709\u7533\u8bf7AI\u96c6\u7fa4\u8282\u70b9\u6743\u9650\u7684\u5b66\u751f\u9700\u8981 \u53d1\u90ae\u4ef6\u7ed9\u738b\u91d1\u78ca\u8001\u5e08 \u5e76\u6284\u9001\u4f60\u7684\u5bfc\u5e08, \u90ae\u4ef6\u5185\u5bb9\u5305\u62ec: \u4f60\u7684\u540d\u5b57 \u4e0a\u79d1\u5927\u90ae\u7bb1 \u8d44\u6e90\u9700\u6c42\u60c5\u51b5 \u9700\u8981\u591a\u957f\u65f6\u95f4 \u539f\u56e0 \u767b\u5f55AI\u96c6\u7fa4 \u7533\u8bf7\u6210\u529f\u540e, \u4f60\u4f1a\u6536\u5230\u7c7b\u4f3c\u5982\u4e0b\u4fe1\u606f: username: piaozx password: 123456 port: 22100 admin_open_port: 31000-31009 \u5176\u4e2d username \u4e3a\u4f60\u7684\u7528\u6237\u540d(\u4f46\u662f\u5728\u767b\u5f55\u65f6\u4e0d\u4f1a\u7528\u5230), password \u662f\u4f60\u7684\u521d\u59cb\u767b\u5f55\u5bc6\u7801, port \u662f\u4f60\u767b\u5f55\u7528\u7684\u7aef\u53e3\u53f7, admin_open_port \u662f\u4e3a\u5f00\u542f\u7f51\u7edc\u670d\u52a1\u9884\u7559\u7684\u7aef\u53e3\u53f7(\u5982 visdom , jupyter ) \u63a5\u4e0b\u6765\u6211\u4eec\u7528ssh\u767b\u5f55\u5373\u53ef(\u6ce8\u610f, \u767b\u5f55\u65f6\u7528\u6237\u540d\u4e3a root ): ssh root@10.19.124.11 -p 22100 windows\u4e0a\u7684cmd\u9ed8\u8ba4\u6ca1\u6709ssh, \u5728\u8fd9\u91cc\u63a8\u8350\u4f7f\u7528 WSL (Windows Subsystem for Linux), \u5177\u4f53\u7f51\u4e0a\u6559\u7a0b\u7528\u5f88\u591a, \u4e0d\u518d\u8d58\u8ff0. # piaozhx @ pzx-mbp in ~ [18:43:17] $ ssh root@10.19.124.11 -p 22100 root@10.19.124.11's password: Welcome to Ubuntu 16.04.4 LTS (GNU/Linux 3.10.0-514.16.1.el7.x86_64 x86_64) * Documentation: https://help.ubuntu.com * Management: https://landscape.canonical.com * Support: https://ubuntu.com/advantage If you have any problem, go to AI server website ADMIN OPEN PORT: 31000-31009 ............................................. Last login: Mon Aug 27 10:30:35 2018 from 10.20.194.83 # root @ piaozx.admin in ~ [12:01:43] $ Alternatively, you can configure public key authentication for fast login without password. {{< admonition title=\"Note\" type=\"note\" >}} You may be asked to change your initial password the first time you login. {{< /admonition >}} The prompt (AI)username@admin:~$ means that you are now in the admin node of AI cluster. Admin node is an intermediate node where you can access all other nodes in the cluster. All other nodes is only accessable though admin node. For example, you can enter ssh node01 to access node01 in the cluster. {{< admonition title=\"Warnning\" type=\"warnning\" >}} Users MUST NOT execute any compute-intensive applications directly on admin node. {{< /admonition >}} How to Find Out GPU Usage NVIDIA provides command line tools nvidia-smi for users to monitor GPU usage. Just enter nvidia-smi in your terminal, then you will get output like following: Fri Jun 30 13:22:13 2017 +-----------------------------------------------------------------------------+ | NVIDIA-SMI 375.26 Driver Version: 375.26 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | |===============================+======================+======================| | 0 GeForce GTX 1080 Off | 0000:02:00.0 Off | N/A | | 27% 31C P0 38W / 180W | 0MiB / 8113MiB | 0% Default | +-------------------------------+----------------------+----------------------+ | 1 GeForce GTX 1080 Off | 0000:03:00.0 Off | N/A | | 27% 34C P0 38W / 180W | 0MiB / 8113MiB | 0% Default | +-------------------------------+----------------------+----------------------+ | 2 GeForce GTX 1080 Off | 0000:83:00.0 Off | N/A | | 27% 28C P0 38W / 180W | 0MiB / 8113MiB | 0% Default | +-------------------------------+----------------------+----------------------+ | 3 GeForce GTX 1080 Off | 0000:84:00.0 Off | N/A | | 0% 29C P0 34W / 180W | 0MiB / 8113MiB | 0% Default | +-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+ | Processes: GPU Memory | | GPU PID Type Process name Usage | |=============================================================================| | No running processes found | +-----------------------------------------------------------------------------+ How To Make Command Running in the Background If you directly run come commands in your terminal, their processes will be termimated once you disconnect from AI cluster. In order to make your command stay alive after you close the terminal session, you have to make your command process run in background using nohup command args & . Optionally, you can specify the file where the stdout will be redirected. Here are some examples: # run a training scripts in the background and redirect stdout to file \"out.txt\" nohup python train.py --lr 0.1 --epochs 100 >> out.txt & Then you can use tailf out.txt to monitor your script's output. You can safely use CTRL-C to terminate tailf command without effect on your script. If you want to terminate your command running in the background, you should first get the process id(PID) of your command. This can be done using ps aux , you will see a list of process running on the node. You can use grep to filter the output, like the following: # find the PID of processes whose name containing key words \"python\" ps aux | grep python You will only see all process whose command line contain key words python . Then, you can get your process PID in the corresponding column of the output. To terminate your command process, enter the following command: kill -9 12345 23456 where 12345 and 23456 are PIDs of the processes you wish to terminate. Working With AI Cluster The Best Practice Access to Internet or Other Nodes Users should note that only admin node have internet access . Therefore if you want to download something from internet, you should download it on admin node. All nodes in the cluster share the same filesystem , which means that once you download something on admin node, you have it on all other nodes. There two kinds of networks in AI cluster: job network and IB network. The former is used in most cases (e.g. ssh login) while the later provides high speed communications between nodes. Hostnames nodeXX are resolved to the job network ip 10.10.10.1XX and inodeXX are resolved to the IB network ip 12.12.12.1XX . Users who need high speed communication between nodes are recommanded to use IB network. {{< admonition title=\"Note\" type=\"note\" >}} Because shared storage uses IB network, heavy usage of IB network may slow down I/O speed. {{< /admonition >}} Request For Sudo Privilege All users should not request for sudo privilege in most situations . Users accustomed to work with their personal computers may like to use sudo apt-get install blablabla to install all softwares and liberaries, however, it is not necessary to use root privilege if you just install them in your own directories. All commonly used liberaries and softwares have already been installed in the system, all users who need extra softwares or libraries should firstly try to install them in their own directory and use environment variables like PATH and LD_LIBRARY_PATH to declare the new software executable file or libraries. The Best Practice For Python Users We highly recommend python users to setup their own anaconda environment . Their are plenty of advantages using anaconda: Easy to install new packages using conda or pip command, without requiring admin privilege. Making users' python environment seperated from system python environment. Some python packages just provide wrappers for some C++ libraries, hence needs underlying C++ liberaries to be installed. Anaconda will handle all these dependencies elegantly. If their are some reasons you really need system python environment and want to install some packages. You SHOULD install it into your home directory with the following command. pip install package-name --user How to Run Applications With GUI Some users may need to use softwares with GUI (e.g. matlab, pycharm), which is possible using ssh X11 forwarding. AI cluster is configured to support X11 forwarding, but users need to add extra lines into their .bashrc file to make X11 forwarding run properly. In order to enable X11 forwarding feature, add the following lines into .bashrc : export XAUTHORITY=/home/$(whoami)/.Xauthority if [ -f \"./DISPLAY\" ] && [ \"$HOSTNAME\" != \"admin\" ] then export DISPLAY=$(cat ./DISPLAY) xauth add $(cat ./DISPLAYSESSION) fi Then user should re-login AI cluster with ssh -X username@10.19.124.11 where the option -X enables X11 forwarding feature. Now you can feel free to run graphics applications, for example, you can try to run matlab and you will see matlab main window on your local PC. The ssh X11 forwarding can be chained, for example, it's possible to run GUI applications on nodes other than admin node. # on your local PC ssh -X username@10.19.124.11 # on admin node ssh -X node01 # then you can run GUI applications like matlab on node01 matlab","title":"Start"},{"location":"start/#_1","text":"\u6240\u6709\u7533\u8bf7AI\u96c6\u7fa4\u8282\u70b9\u6743\u9650\u7684\u5b66\u751f\u9700\u8981 \u53d1\u90ae\u4ef6\u7ed9\u738b\u91d1\u78ca\u8001\u5e08 \u5e76\u6284\u9001\u4f60\u7684\u5bfc\u5e08, \u90ae\u4ef6\u5185\u5bb9\u5305\u62ec: \u4f60\u7684\u540d\u5b57 \u4e0a\u79d1\u5927\u90ae\u7bb1 \u8d44\u6e90\u9700\u6c42\u60c5\u51b5 \u9700\u8981\u591a\u957f\u65f6\u95f4 \u539f\u56e0","title":"\u7533\u8bf7\u96c6\u7fa4\u8d26\u53f7\u53ca\u6743\u9650"},{"location":"start/#ai","text":"\u7533\u8bf7\u6210\u529f\u540e, \u4f60\u4f1a\u6536\u5230\u7c7b\u4f3c\u5982\u4e0b\u4fe1\u606f: username: piaozx password: 123456 port: 22100 admin_open_port: 31000-31009 \u5176\u4e2d username \u4e3a\u4f60\u7684\u7528\u6237\u540d(\u4f46\u662f\u5728\u767b\u5f55\u65f6\u4e0d\u4f1a\u7528\u5230), password \u662f\u4f60\u7684\u521d\u59cb\u767b\u5f55\u5bc6\u7801, port \u662f\u4f60\u767b\u5f55\u7528\u7684\u7aef\u53e3\u53f7, admin_open_port \u662f\u4e3a\u5f00\u542f\u7f51\u7edc\u670d\u52a1\u9884\u7559\u7684\u7aef\u53e3\u53f7(\u5982 visdom , jupyter ) \u63a5\u4e0b\u6765\u6211\u4eec\u7528ssh\u767b\u5f55\u5373\u53ef(\u6ce8\u610f, \u767b\u5f55\u65f6\u7528\u6237\u540d\u4e3a root ): ssh root@10.19.124.11 -p 22100 windows\u4e0a\u7684cmd\u9ed8\u8ba4\u6ca1\u6709ssh, \u5728\u8fd9\u91cc\u63a8\u8350\u4f7f\u7528 WSL (Windows Subsystem for Linux), \u5177\u4f53\u7f51\u4e0a\u6559\u7a0b\u7528\u5f88\u591a, \u4e0d\u518d\u8d58\u8ff0. # piaozhx @ pzx-mbp in ~ [18:43:17] $ ssh root@10.19.124.11 -p 22100 root@10.19.124.11's password: Welcome to Ubuntu 16.04.4 LTS (GNU/Linux 3.10.0-514.16.1.el7.x86_64 x86_64) * Documentation: https://help.ubuntu.com * Management: https://landscape.canonical.com * Support: https://ubuntu.com/advantage If you have any problem, go to AI server website ADMIN OPEN PORT: 31000-31009 ............................................. Last login: Mon Aug 27 10:30:35 2018 from 10.20.194.83 # root @ piaozx.admin in ~ [12:01:43] $ Alternatively, you can configure public key authentication for fast login without password. {{< admonition title=\"Note\" type=\"note\" >}} You may be asked to change your initial password the first time you login. {{< /admonition >}} The prompt (AI)username@admin:~$ means that you are now in the admin node of AI cluster. Admin node is an intermediate node where you can access all other nodes in the cluster. All other nodes is only accessable though admin node. For example, you can enter ssh node01 to access node01 in the cluster. {{< admonition title=\"Warnning\" type=\"warnning\" >}} Users MUST NOT execute any compute-intensive applications directly on admin node. {{< /admonition >}}","title":"\u767b\u5f55AI\u96c6\u7fa4"},{"location":"start/#how-to-find-out-gpu-usage","text":"NVIDIA provides command line tools nvidia-smi for users to monitor GPU usage. Just enter nvidia-smi in your terminal, then you will get output like following: Fri Jun 30 13:22:13 2017 +-----------------------------------------------------------------------------+ | NVIDIA-SMI 375.26 Driver Version: 375.26 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | |===============================+======================+======================| | 0 GeForce GTX 1080 Off | 0000:02:00.0 Off | N/A | | 27% 31C P0 38W / 180W | 0MiB / 8113MiB | 0% Default | +-------------------------------+----------------------+----------------------+ | 1 GeForce GTX 1080 Off | 0000:03:00.0 Off | N/A | | 27% 34C P0 38W / 180W | 0MiB / 8113MiB | 0% Default | +-------------------------------+----------------------+----------------------+ | 2 GeForce GTX 1080 Off | 0000:83:00.0 Off | N/A | | 27% 28C P0 38W / 180W | 0MiB / 8113MiB | 0% Default | +-------------------------------+----------------------+----------------------+ | 3 GeForce GTX 1080 Off | 0000:84:00.0 Off | N/A | | 0% 29C P0 34W / 180W | 0MiB / 8113MiB | 0% Default | +-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+ | Processes: GPU Memory | | GPU PID Type Process name Usage | |=============================================================================| | No running processes found | +-----------------------------------------------------------------------------+","title":"How to Find Out GPU Usage"},{"location":"start/#how-to-make-command-running-in-the-background","text":"If you directly run come commands in your terminal, their processes will be termimated once you disconnect from AI cluster. In order to make your command stay alive after you close the terminal session, you have to make your command process run in background using nohup command args & . Optionally, you can specify the file where the stdout will be redirected. Here are some examples: # run a training scripts in the background and redirect stdout to file \"out.txt\" nohup python train.py --lr 0.1 --epochs 100 >> out.txt & Then you can use tailf out.txt to monitor your script's output. You can safely use CTRL-C to terminate tailf command without effect on your script. If you want to terminate your command running in the background, you should first get the process id(PID) of your command. This can be done using ps aux , you will see a list of process running on the node. You can use grep to filter the output, like the following: # find the PID of processes whose name containing key words \"python\" ps aux | grep python You will only see all process whose command line contain key words python . Then, you can get your process PID in the corresponding column of the output. To terminate your command process, enter the following command: kill -9 12345 23456 where 12345 and 23456 are PIDs of the processes you wish to terminate.","title":"How To Make Command Running in the Background"},{"location":"start/#working-with-ai-cluster-the-best-practice","text":"","title":"Working With AI Cluster The Best Practice"},{"location":"start/#access-to-internet-or-other-nodes","text":"Users should note that only admin node have internet access . Therefore if you want to download something from internet, you should download it on admin node. All nodes in the cluster share the same filesystem , which means that once you download something on admin node, you have it on all other nodes. There two kinds of networks in AI cluster: job network and IB network. The former is used in most cases (e.g. ssh login) while the later provides high speed communications between nodes. Hostnames nodeXX are resolved to the job network ip 10.10.10.1XX and inodeXX are resolved to the IB network ip 12.12.12.1XX . Users who need high speed communication between nodes are recommanded to use IB network. {{< admonition title=\"Note\" type=\"note\" >}} Because shared storage uses IB network, heavy usage of IB network may slow down I/O speed. {{< /admonition >}}","title":"Access to Internet or Other Nodes"},{"location":"start/#request-for-sudo-privilege","text":"All users should not request for sudo privilege in most situations . Users accustomed to work with their personal computers may like to use sudo apt-get install blablabla to install all softwares and liberaries, however, it is not necessary to use root privilege if you just install them in your own directories. All commonly used liberaries and softwares have already been installed in the system, all users who need extra softwares or libraries should firstly try to install them in their own directory and use environment variables like PATH and LD_LIBRARY_PATH to declare the new software executable file or libraries.","title":"Request For Sudo Privilege"},{"location":"start/#the-best-practice-for-python-users","text":"We highly recommend python users to setup their own anaconda environment . Their are plenty of advantages using anaconda: Easy to install new packages using conda or pip command, without requiring admin privilege. Making users' python environment seperated from system python environment. Some python packages just provide wrappers for some C++ libraries, hence needs underlying C++ liberaries to be installed. Anaconda will handle all these dependencies elegantly. If their are some reasons you really need system python environment and want to install some packages. You SHOULD install it into your home directory with the following command. pip install package-name --user","title":"The Best Practice For Python Users"},{"location":"start/#how-to-run-applications-with-gui","text":"Some users may need to use softwares with GUI (e.g. matlab, pycharm), which is possible using ssh X11 forwarding. AI cluster is configured to support X11 forwarding, but users need to add extra lines into their .bashrc file to make X11 forwarding run properly. In order to enable X11 forwarding feature, add the following lines into .bashrc : export XAUTHORITY=/home/$(whoami)/.Xauthority if [ -f \"./DISPLAY\" ] && [ \"$HOSTNAME\" != \"admin\" ] then export DISPLAY=$(cat ./DISPLAY) xauth add $(cat ./DISPLAYSESSION) fi Then user should re-login AI cluster with ssh -X username@10.19.124.11 where the option -X enables X11 forwarding feature. Now you can feel free to run graphics applications, for example, you can try to run matlab and you will see matlab main window on your local PC. The ssh X11 forwarding can be chained, for example, it's possible to run GUI applications on nodes other than admin node. # on your local PC ssh -X username@10.19.124.11 # on admin node ssh -X node01 # then you can run GUI applications like matlab on node01 matlab","title":"How to Run Applications With GUI"}]}